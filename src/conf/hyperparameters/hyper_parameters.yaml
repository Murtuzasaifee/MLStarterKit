decision_tree:
  criterion: ['squared_error', 'friedman_mse', 'absolute_error', 'poisson']
  splitter: ['best', 'random']
  max_features: ['sqrt', 'log2']

random_forest:
  criterion: ['squared_error', 'friedman_mse', 'absolute_error', 'poisson']
  max_features: ['sqrt', 'log2', null]
  n_estimators: [8, 16, 32, 64, 128, 256]

gradient_boosting:
  loss: ['squared_error', 'huber', 'absolute_error', 'quantile']
  learning_rate: [0.1, 0.01, 0.05, 0.001]
  subsample: [0.6, 0.7, 0.75, 0.8, 0.85, 0.9]
  criterion: ['squared_error', 'friedman_mse']
  max_features: ['sqrt', 'log2']
  n_estimators: [8, 16, 32, 64, 128, 256]

linear_regression: {}

xgb_regressor:
  learning_rate: [0.1, 0.01, 0.05, 0.001]
  n_estimators: [8, 16, 32, 64, 128, 256]

cat_boosting_regressor:
  depth: [6, 8, 10]
  learning_rate: [0.01, 0.05, 0.1]
  iterations: [30, 50, 100]

ada_boost_regressor:
  learning_rate: [0.1, 0.01, 0.5, 0.001]
  loss: ['linear', 'square', 'exponential']
  n_estimators: [8, 16, 32, 64, 128, 256]